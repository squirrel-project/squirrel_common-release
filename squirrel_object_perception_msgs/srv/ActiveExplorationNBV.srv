# Determines the next best view in order to improve the classification
# of observed objects
# author: Tim Patten, t.patten@acfr.usyd.edu.au

# the current pose of the robot in baselink frame
geometry_msgs/Pose robot_pose

# the variance value used in utility calculation (default is 0.5)
float32 variance

# the original full view organized point cloud
sensor_msgs/PointCloud2 cloud

# the indices of the segmented clusters
std_msgs/Int32MultiArray[] clusters_indices

# the list of classification results for clusters
squirrel_object_perception_msgs/Classification[] class_results

# the occupancy map of the environment
octomap_msgs/Octomap map

# the list of candidate viewpoints in the map (optional, but if not specified then need to set the parameters below to generate the locations)
geometry_msgs/Point[] locations

# the height of the onboard camera above the robot pose (optional, but required if candidate viewpoints is empty)
float32 camera_height

# the radius of the robot (optional, but required if candidate viewpoints is empty)
float32 robot_radius

# the distance from viewpoint location to the center of an object (optional, but required if candidate viewpoints is empty)
float32 distance_from_center

# the number of viewpoints per object to generate (optional, but required if candidate viewpoints is empty)
uint32 num_locations

# planning type method selection
# TRUE considers the visibility due to occlusions, this is slow but possibly more accurate
# FALSE does not consider occlusions, this is fast but only considers class performance and not the actual visibility
bool occlusions

---

# the index into locations with highest utility (-1 for error)
uint32 nbv_ix

# the list of candidate viewpoints in the map that are generated if not originally specified
geometry_msgs/Point[] generated_locations

# the list of utility values for each location
float32[] utilities
